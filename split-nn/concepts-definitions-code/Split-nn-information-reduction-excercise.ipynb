{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information, Self-information and Split Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this excersise we want to see how split-learning is helping privacy by decreasing the information content in a raw input. This is a simplified example, just to help the understanding of the concepts in this lesson. \n",
    "\n",
    "We will be using MNIST data for this excersise. We will first download and load the data. Then, we will load a pretrained small DNN. Our aim is to compare the information in the raw inputs of the MNIST test set, with the information in the output of the final convolution layer, to see if there is information degredation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from lenet_5 import LeNet5_5\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "BATCH_TEST_SIZE = 1024\n",
    "data_train = MNIST('./data/mnist',\n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize((32, 32)),\n",
    "                       transforms.ToTensor()]))\n",
    "data_test = MNIST('./data/mnist',\n",
    "                  train=False,\n",
    "                  download=True,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.Resize((32, 32)),\n",
    "                      transforms.ToTensor()]))\n",
    "data_train_loader = DataLoader(data_train, batch_size = BATCH_SIZE , shuffle=True, num_workers=8)\n",
    "data_test_loader = DataLoader(data_test,  batch_size = BATCH_TEST_SIZE, num_workers=8)\n",
    "data_test_loader2 = DataLoader(data_test,  batch_size = 1, num_workers=0)\n",
    "\n",
    "TRAIN_SIZE = len(data_train_loader.dataset)\n",
    "TEST_SIZE = len(data_test_loader.dataset)\n",
    "NUM_BATCHES = len(data_train_loader)\n",
    "NUM_TEST_BATCHES = len(data_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = LeNet5_5()\n",
    "model_loaded.load_state_dict(torch.load(\"./LeNet-saved-5\"))\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate (net, criterion):\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(data_test_loader):\n",
    "        labels = (labels > 5).long()\n",
    "        output = net(images)\n",
    "        avg_loss += criterion(output, labels).sum()\n",
    "        pred = output.detach().max(1)[1]\n",
    "        total_correct += pred.eq(labels.view_as(pred)).sum()\n",
    "\n",
    "    avg_loss /= len(data_test)\n",
    "    print('Test Avg. Loss: %f, Accuracy: %f' % (avg_loss.detach().cpu().item(), float(total_correct) / len(data_test)))\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run validate to check the accuracy of the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Avg. Loss: 0.000023, Accuracy: 0.992900\n"
     ]
    }
   ],
   "source": [
    "validate (model_loaded, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting and measuring information content\n",
    "\n",
    "At this point, we want to split the network to two parts, and observe how different the information content of the original images and the intermediate activations are. We chose the last convolution layer of the pre-trained model we had as the splitting point. We will feed all the test data to the convolutions, and save their outputs so that we can later use them to quantitatively measure the bits of information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the raw images and the intermediate activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs =[]\n",
    "intermediate_activations = []\n",
    "total_correct = 0\n",
    "\n",
    "model_loaded.eval()\n",
    "for i, (images, labels) in enumerate(data_test_loader2):\n",
    "    \n",
    "    \n",
    "    imgs.append(((np.reshape(np.squeeze(images.detach().numpy()), (1,-1)) )))\n",
    "    x= images\n",
    "    x = model_loaded.convnet(x)      \n",
    "    \n",
    "    intermediate_activations.append(((np.reshape(np.squeeze(x.detach().numpy()), (1,-1)) )))\n",
    "    \n",
    "    np.save(\"images\", np.array(imgs).squeeze(1))\n",
    "    np.save(\"intermediate_act\", np.array(intermediate_activations).squeeze(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the Information Toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,'./ite-repo')\n",
    "import ite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### loading numpy files and calculating mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1024)\n",
      "(10000, 120)\n"
     ]
    }
   ],
   "source": [
    "images_raw=np.load(\"images.npy\")\n",
    "print(images_raw.shape)\n",
    "intermediate_activation=np.load(\"intermediate_act.npy\")\n",
    "print(intermediate_activation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutual Information function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = ite.cost.MIShannon_DKL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2048)\n",
      "730.6892832072778\n"
     ]
    }
   ],
   "source": [
    "ds = np.array([1024, 1024])\n",
    "y = np.concatenate((images_raw, images_raw),axis=1)\n",
    "print(y.shape)\n",
    "i = co.estimation(y, ds) \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1144)\n",
      "303.22723470399853\n"
     ]
    }
   ],
   "source": [
    "ds = np.array([1024, 120])\n",
    "y = np.concatenate((images_raw, intermediate_activation),axis=1)\n",
    "print(y.shape)\n",
    "i = co.estimation(y, ds) \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation and conclusion: We can see that the raw image contained 730 bits of self-information, whereas the intermediate activations only contain 303 bits of information that was originally in the raw image (the 730 bits). This shows that the first layers of the neural network, alone, have degraded more than half of the original information in the raw input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
